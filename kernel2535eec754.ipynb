{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dataset from https://www.kaggle.com/slothkong/10-monkey-species","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\n\ntrain_dir='../input/10-monkey-species/training/training'\nval_dir='../input/10-monkey-species/validation/validation'\n\ncols = ['Label','Latin Name', 'Common Name','Train Images', 'Validation Images']\nlabels = pd.read_csv(\"../input/10-monkey-species/monkey_labels.txt\", names=cols, skiprows=1)\nlabels\n\nlabels=labels['Common Name']\nlabels\n","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"0     mantled_howler                \n1     patas_monkey                  \n2     bald_uakari                   \n3     japanese_macaque              \n4     pygmy_marmoset                \n5     white_headed_capuchin         \n6     silvery_marmoset              \n7     common_squirrel_monkey        \n8     black_headed_night_monkey     \n9     nilgiri_langur                \nName: Common Name, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"height = 256\nwidth = 256\nbatch_sizes = 24\nnum_classes = 10\ntrain_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input,\n                                                                       rotation_range=40,\n                                                                       width_shift_range=0.2,\n                                                                       height_shift_range=0.2,\n                                                                       shear_range=0.2,\n                                                                       zoom_range=0.2,\n                                                                       horizontal_flip=True,\n                                                                       fill_mode='nearest')\n\ntrain_generator = train_data_generator.flow_from_directory(train_dir, target_size=(height, width),\n                                                           batch_size = batch_sizes,\n                                                           seed = 7,shuffle = True,\n                                                           class_mode='categorical')\n\nvalidation_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=tf.keras.applications.resnet50.preprocess_input)\n\nvalidation_generator = validation_data_generator.flow_from_directory(val_dir,\n                                                                     target_size=(height, width),\n                                                                     batch_size=batch_sizes,shuffle = False,\n                                                                     seed = 7, class_mode='categorical')","execution_count":11,"outputs":[{"output_type":"stream","text":"Found 1098 images belonging to 10 classes.\nFound 272 images belonging to 10 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"transfer_model = tf.keras.models.Sequential()\ntransfer_model.add(tf.keras.applications.ResNet50(include_top = False,\n                                                  pooling = 'avg',\n                                                  weights = 'imagenet'))\ntransfer_model.add(tf.keras.layers.Dense(1024,activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\ntransfer_model.add(tf.keras.layers.Dense(512,activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\ntransfer_model.add(tf.keras.layers.Dense(256,activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\ntransfer_model.add(tf.keras.layers.Dense(128,activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\ntransfer_model.add(tf.keras.layers.Dense(64,activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\ntransfer_model.add(tf.keras.layers.Dense(32,activation=tf.keras.layers.LeakyReLU(alpha=0.1)))\ntransfer_model.add(tf.keras.layers.Dense(num_classes, activation = 'softmax'))\ntransfer_model.layers[0].trainable = False\n\ntransfer_model.compile(loss=\"categorical_crossentropy\",\n             optimizer=\"adam\", metrics=['accuracy'])\ntransfer_model.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 2048)              23587712  \n_________________________________________________________________\ndense_8 (Dense)              (None, 1024)              2098176   \n_________________________________________________________________\ndense_9 (Dense)              (None, 512)               524800    \n_________________________________________________________________\ndense_10 (Dense)             (None, 256)               131328    \n_________________________________________________________________\ndense_11 (Dense)             (None, 128)               32896     \n_________________________________________________________________\ndense_12 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndense_13 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_14 (Dense)             (None, 10)                330       \n=================================================================\nTotal params: 26,385,578\nTrainable params: 2,797,866\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 25\nbatch_size = 128\nhistory = transfer_model.fit_generator(train_generator,\n                                           steps_per_epoch = (train_generator.samples)//batch_size,\n                                           epochs = epochs,\n                                           validation_data = validation_generator,\n                                           validation_steps=(validation_generator.samples)//batch_size )","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/25\n8/8 [==============================] - 30s 4s/step - loss: 1.9000 - accuracy: 0.3385 - val_loss: 0.2607 - val_accuracy: 1.0000\nEpoch 2/25\n8/8 [==============================] - 28s 3s/step - loss: 1.1559 - accuracy: 0.6094 - val_loss: 0.1003 - val_accuracy: 1.0000\nEpoch 3/25\n8/8 [==============================] - 28s 4s/step - loss: 0.5328 - accuracy: 0.8438 - val_loss: 0.0270 - val_accuracy: 1.0000\nEpoch 4/25\n8/8 [==============================] - 28s 4s/step - loss: 0.5472 - accuracy: 0.8229 - val_loss: 0.0371 - val_accuracy: 1.0000\nEpoch 5/25\n8/8 [==============================] - 28s 4s/step - loss: 0.4166 - accuracy: 0.8750 - val_loss: 0.0095 - val_accuracy: 1.0000\nEpoch 6/25\n8/8 [==============================] - 27s 3s/step - loss: 0.2597 - accuracy: 0.9086 - val_loss: 0.1315 - val_accuracy: 0.9375\nEpoch 7/25\n8/8 [==============================] - 27s 3s/step - loss: 0.1959 - accuracy: 0.9462 - val_loss: 0.0659 - val_accuracy: 0.9792\nEpoch 8/25\n8/8 [==============================] - 28s 4s/step - loss: 0.3031 - accuracy: 0.9115 - val_loss: 0.2116 - val_accuracy: 0.9167\nEpoch 9/25\n8/8 [==============================] - 27s 3s/step - loss: 0.1754 - accuracy: 0.9247 - val_loss: 0.0370 - val_accuracy: 0.9792\nEpoch 10/25\n8/8 [==============================] - 28s 4s/step - loss: 0.1825 - accuracy: 0.9635 - val_loss: 0.0666 - val_accuracy: 0.9792\nEpoch 11/25\n8/8 [==============================] - 28s 3s/step - loss: 0.1816 - accuracy: 0.9583 - val_loss: 0.0415 - val_accuracy: 0.9792\nEpoch 12/25\n8/8 [==============================] - 28s 4s/step - loss: 0.1900 - accuracy: 0.9479 - val_loss: 0.0031 - val_accuracy: 1.0000\nEpoch 13/25\n8/8 [==============================] - 28s 3s/step - loss: 0.1301 - accuracy: 0.9688 - val_loss: 0.2420 - val_accuracy: 0.9167\nEpoch 14/25\n1/8 [==>...........................] - ETA: 0s - loss: 0.2454 - accuracy: 0.9583","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}